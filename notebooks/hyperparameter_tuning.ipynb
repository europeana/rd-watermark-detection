{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08d85bc-7d77-4771-ae2b-67d029f730af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from filelock import FileLock\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.accuracy = Accuracy(task=\"binary\", num_classes=10, top_k=1)\n",
    "\n",
    "        output_dim = 2\n",
    "\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, output_dim)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "        self.lr = config[\"lr\"]\n",
    "\n",
    "        self.eval_loss = []\n",
    "        self.eval_accuracy = []\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        self.log(\"ptl/train_accuracy\", accuracy)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        self.eval_loss.append(loss)\n",
    "        self.eval_accuracy.append(accuracy)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.eval_loss).mean()\n",
    "        avg_acc = torch.stack(self.eval_accuracy).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss, sync_dist=True)\n",
    "        self.log(\"ptl/val_accuracy\", avg_acc, sync_dist=True)\n",
    "        self.eval_loss.clear()\n",
    "        self.eval_accuracy.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, imgs,labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img_list = imgs\n",
    "        self.labels = labels\n",
    "        #self.encoding_dict = le.classes_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.img_list[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,label\n",
    "\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=128,data_dir=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.25),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        self.test_transforms = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_dir = Path(self.data_dir)\n",
    "        imgs = np.array([str(p) for p in data_dir.rglob(\"*/*\")])\n",
    "        labels = np.array([Path(p).parent.name for p in imgs])\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        _labels = le.fit_transform(labels)\n",
    "        classes = le.classes_\n",
    "        labels = F.one_hot(torch.from_numpy(_labels)).float()\n",
    "\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(imgs, labels, test_size=0.2)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2)\n",
    "\n",
    "        self.train_dataset = TrainingDataset(X_train,y_train,transform = self.train_transforms)\n",
    "        self.val_dataset = TrainingDataset(X_val,y_val,transform = self.test_transforms)\n",
    "        self.test_dataset = TrainingDataset(X_test,y_test,transform = self.test_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=1)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4601593b-7c00-456b-a0ca-03d07dc88529",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/storage/data/labeled_4312'\n",
    "\n",
    "default_config = {\n",
    "    \"lr\": 1e-3,\n",
    "}\n",
    "\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([4, 8, 16 ]),\n",
    "}\n",
    "\n",
    "# The maximum training epochs\n",
    "num_epochs = 1\n",
    "\n",
    "# Number of sampls from parameter space\n",
    "num_samples = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddef4ef4-7b55-49ea-8423-21d30951e345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-01 19:11:29</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:54.56        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.0/62.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 1.000: 0.5121503472328186<br>Logical resource usage: 2.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_ea6f7_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00000_0_batch_size=32,lr=0.0003_2023-11-01_19-07-35/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">   train_loop_config/ba\n",
       "tch_size</th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ptl/train_loss</th><th style=\"text-align: right;\">  ptl/train_accuracy</th><th style=\"text-align: right;\">  ptl/val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_ea6f7_00001</td><td>TERMINATED</td><td>192.168.112.2:28422</td><td style=\"text-align: right;\"> 4</td><td style=\"text-align: right;\">           0.0108818  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         99.5492</td><td style=\"text-align: right;\">        1.31326 </td><td style=\"text-align: right;\">            0       </td><td style=\"text-align: right;\">      0.834938</td></tr>\n",
       "<tr><td>TorchTrainer_ea6f7_00002</td><td>TERMINATED</td><td>192.168.112.2:28610</td><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">           0.000322598</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        103.129 </td><td style=\"text-align: right;\">        0.601653</td><td style=\"text-align: right;\">            0.714286</td><td style=\"text-align: right;\">      0.689309</td></tr>\n",
       "<tr><td>TorchTrainer_ea6f7_00000</td><td>ERROR     </td><td>192.168.112.2:28260</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">           0.000259862</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">              </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=28260)\u001b[0m Starting distributed worker processes: ['28307 (192.168.112.2)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:07:43,922 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 3849654272; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m Missing logger folder: /root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00000_0_batch_size=32,lr=0.0003_2023-11-01_19-07-35/lightning_logs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m   | Name     | Type           | Params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 0 | accuracy | BinaryAccuracy | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 1 | model    | ResNet         | 11.2 M\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 2 | sm       | Softmax        | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 11.2 M    Trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 11.2 M    Total params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m 44.710    Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28307)\u001b[0m \u0000\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:07:53,930 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301733376; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "2023-11-01 19:07:57,910\tERROR tune_controller.py:1502 -- Trial task failed for trial TorchTrainer_ea6f7_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2547, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=28260, ip=192.168.112.2, actor_id=637cc1018c67a88f9da16f6801000000, repr=TorchTrainer)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py\", line 400, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n",
      "    ray.get(object_ref)\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=28307, ip=192.168.112.2, actor_id=dc9f94438881d500cd5bc33f01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7fe949638700>)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 108, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=28307, ip=192.168.112.2, actor_id=dc9f94438881d500cd5bc33f01000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7fe949638700>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/train/_internal/worker_group.py\", line 33, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n",
      "    train_func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_27897/3978880121.py\", line 14, in train_func\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 545, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 581, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1036, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 202, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fetchers.py\", line 127, in __next__\n",
      "    batch = super().__next__()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fetchers.py\", line 56, in __next__\n",
      "    batch = next(self.iterator)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 326, in __next__\n",
      "    out = next(self._iterator)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 74, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1294, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1145, in _try_get_data\n",
      "    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n",
      "RuntimeError: DataLoader worker (pid(s) 28402) exited unexpectedly\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=28422)\u001b[0m Starting distributed worker processes: ['28460 (192.168.112.2)']\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:03,936 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301651456; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m Missing logger folder: /root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00001_1_batch_size=4,lr=0.0109_2023-11-01_19-07-35/lightning_logs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m   | Name     | Type           | Params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 0 | accuracy | BinaryAccuracy | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 1 | model    | ResNet         | 11.2 M\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 2 | sm       | Softmax        | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 11.2 M    Trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 11.2 M    Total params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m 44.710    Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:13,943 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301602304; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:23,951 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301602304; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:33,958 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301569536; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:43,965 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301536768; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m /usr/local/lib/python3.8/dist-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (142460340 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:08:53,973 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301532672; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:03,981 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301524480; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:13,988 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301520384; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:23,996 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301516288; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:34,003 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1301483520; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28460)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00001_1_batch_size=4,lr=0.0109_2023-11-01_19-07-35/checkpoint_000000)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:44,011 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1167147008; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=28610)\u001b[0m Starting distributed worker processes: ['28648 (192.168.112.2)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m Missing logger folder: /root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00002_2_batch_size=8,lr=0.0003_2023-11-01_19-07-35/lightning_logs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m   | Name     | Type           | Params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 0 | accuracy | BinaryAccuracy | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 1 | model    | ResNet         | 11.2 M\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 2 | sm       | Softmax        | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m --------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 11.2 M    Trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 11.2 M    Total params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m 44.710    Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:09:54,018 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1167044608; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m /usr/local/lib/python3.8/dist-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (142460340 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:04,024 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1167036416; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:14,029 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1167032320; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:24,036 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1167020032; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:34,043 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166991360; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:44,051 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166962688; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:10:54,059 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166950400; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:11:04,066 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166946304; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:11:14,074 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166946304; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:11:24,082 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1166938112; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=28648)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/TorchTrainer_2023-11-01_19-07-32/TorchTrainer_ea6f7_00002_2_batch_size=8,lr=0.0003_2023-11-01_19-07-35/checkpoint_000000)\n",
      "2023-11-01 19:11:29,684\tERROR tune.py:1139 -- Trials did not complete: [TorchTrainer_ea6f7_00000]\n",
      "2023-11-01 19:11:29,685\tINFO tune.py:1143 -- Total run time: 234.60 seconds (234.56 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "def train_func(config):\n",
    "    dm = DataModule(batch_size=config[\"batch_size\"],data_dir = data_dir)\n",
    "    model = Classifier(config)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=1, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=\"ptl/val_accuracy\",\n",
    "        checkpoint_score_order=\"max\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define a TorchTrainer without hyper-parameters for Tuner\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "def tune_mnist_asha(num_samples=10):\n",
    "    scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": search_space},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"ptl/val_accuracy\",\n",
    "            mode=\"max\",\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()\n",
    "\n",
    "\n",
    "results = tune_mnist_asha(num_samples=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3beda533-9c62-4cca-a864-2efd401d43f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl/train_loss</th>\n",
       "      <th>ptl/train_accuracy</th>\n",
       "      <th>ptl/val_loss</th>\n",
       "      <th>ptl/val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>config/train_loop_config/lr</th>\n",
       "      <th>config/train_loop_config/batch_size</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.313262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834938</td>\n",
       "      <td>0.478324</td>\n",
       "      <td>0</td>\n",
       "      <td>690</td>\n",
       "      <td>1698865782</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.549214</td>\n",
       "      <td>28422</td>\n",
       "      <td>68a769195ff1</td>\n",
       "      <td>192.168.112.2</td>\n",
       "      <td>99.549214</td>\n",
       "      <td>1</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>4</td>\n",
       "      <td>ea6f7_00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601653</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>1698865889</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.128893</td>\n",
       "      <td>28610</td>\n",
       "      <td>68a769195ff1</td>\n",
       "      <td>192.168.112.2</td>\n",
       "      <td>103.128893</td>\n",
       "      <td>1</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>8</td>\n",
       "      <td>ea6f7_00002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ptl/train_loss  ptl/train_accuracy  ptl/val_loss  ptl/val_accuracy  epoch  \\\n",
       "0        1.313262            0.000000      0.834938          0.478324      0   \n",
       "1        0.601653            0.714286      0.689309          0.545977      0   \n",
       "\n",
       "   step   timestamp  should_checkpoint  done  training_iteration  ...  \\\n",
       "0   690  1698865782               True  True                   1  ...   \n",
       "1   345  1698865889               True  True                   1  ...   \n",
       "\n",
       "  time_total_s    pid      hostname        node_ip  time_since_restore  \\\n",
       "0    99.549214  28422  68a769195ff1  192.168.112.2           99.549214   \n",
       "1   103.128893  28610  68a769195ff1  192.168.112.2          103.128893   \n",
       "\n",
       "  iterations_since_restore checkpoint_dir_name  config/train_loop_config/lr  \\\n",
       "0                        1   checkpoint_000000                     0.010882   \n",
       "1                        1   checkpoint_000000                     0.000323   \n",
       "\n",
       "   config/train_loop_config/batch_size       logdir  \n",
       "0                                    4  ea6f7_00001  \n",
       "1                                    8  ea6f7_00002  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:12:34,133 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032515584; capacity: 468438253568. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "df = results.get_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2267fc2-21b9-423f-889d-80de30517f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:13:54,190 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032425472; capacity: 468438253568. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "best_result = results.get_best_result()\n",
    "loss = best_result.metrics['ptl/val_loss']\n",
    "acc = best_result.metrics['ptl/val_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23737786-1bf5-4a85-bdb1-8bcf06f41911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6893086433410645"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a59e52-33e4-44bd-b57d-7be91348cd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.545976996421814"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:04,197 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032425472; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:14,204 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032400896; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:24,211 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032392704; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:34,218 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032368128; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:44,225 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032359936; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:14:54,232 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032351744; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:04,239 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032347648; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:14,247 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032339456; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:24,254 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032335360; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:34,262 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032310784; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:44,269 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032278016; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:15:54,277 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032269824; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:04,285 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032269824; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:14,292 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032245248; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:24,300 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032232960; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:34,307 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032192000; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:44,315 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032175616; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:16:54,322 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032159232; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:04,330 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032155136; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:14,338 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032155136; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:24,345 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032146944; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:34,353 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032110080; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:44,361 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032081408; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:17:54,369 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032069120; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:04,376 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032069120; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:14,384 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032056832; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:24,391 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032048640; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:34,399 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1032011776; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:44,406 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031995392; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:18:54,414 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031979008; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:04,421 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031979008; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:14,429 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031974912; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:24,436 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031966720; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:34,443 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031938048; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:44,449 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031929856; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:19:54,455 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031917568; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:04,462 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031909376; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:14,468 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031897088; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:24,474 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031892992; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:34,481 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031856128; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:44,488 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031823360; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:20:54,495 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031815168; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:04,502 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031811072; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:14,509 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031811072; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:24,516 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031798784; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:34,524 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031766016; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:44,531 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031761920; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:21:54,538 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031761920; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:04,545 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031757824; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:14,552 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031757824; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:24,560 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031675904; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:34,568 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031368704; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:44,575 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031294976; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:22:54,583 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031282688; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:04,591 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031282688; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:14,599 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031274496; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:24,606 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031258112; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:34,614 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031237632; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:44,622 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031225344; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:23:54,629 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031237632; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:04,636 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031229440; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:14,644 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031229440; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:24,652 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1031221248; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:34,659 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030926336; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:44,666 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030762496; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:24:54,674 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030750208; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:04,681 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030742016; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:14,689 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030742016; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:24,696 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030737920; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:34,704 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030647808; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:44,711 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030631424; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:25:54,719 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030623232; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:26:04,726 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030619136; capacity: 468438253568. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-01 19:26:14,732 E 27995 28007] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-11-01_19-07-32_206593_27897 is over 95% full, available space: 1030606848; capacity: 468438253568. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584a260-3a7f-4006-88d7-47fac4958015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0e43f-4f05-49f4-8f47-9a554e026c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6d133-a72b-47d7-846a-e7fa05c353bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bf695-704b-4b6a-86c3-b09187621b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
