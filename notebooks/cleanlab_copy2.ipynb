{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e674b1-b4ae-41ff-a804-030f26e27db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array(['/storage/data/labeled_6999/watermark/[ph]11625[ph]RBINSOPENUP_RBINS_BELGIUM_3204.jpg',\n",
      "       '/storage/data/labeled_6999/watermark/[ph]431[ph]https___www_searchculture_gr_aggregator_edm_DigCollMIET_000119_694449.jpg',\n",
      "       '/storage/data/labeled_6999/watermark/[ph]2024905[ph]photography_ProvidedCHO_NALIS_Foundation_F13515185290071.jpg',\n",
      "       ...,\n",
      "       '/storage/data/labeled_6999/no_watermark/[ph]92062[ph]BibliographicResource_1000126154170.jpg',\n",
      "       '/storage/data/labeled_6999/no_watermark/[ph]92064[ph]bildarchivaustria_Preview_1234180.jpg',\n",
      "       '/storage/data/labeled_6999/no_watermark/[ph]951[ph]Culturalia_96dda327_cf60_4988_aa38_5c6b5b81d9ce.jpg'],\n",
      "      dtype='<U179'), 'label': array([1, 1, 1, ..., 0, 0, 0])}\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding dark, light, low_information, odd_aspect_ratio, odd_size, grayscale, blurry images ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111e7938f63d4e99b180fe739a4f1df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in checking for image issues: 'str' object has no attribute 'size'\n",
      "\n",
      "Audit complete. 1171 issues found in the dataset.\n",
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "    issue_type  num_issues\n",
      "         label         887\n",
      "       outlier         154\n",
      "near_duplicate         129\n",
      "       non_iid           1\n",
      "\n",
      "Dataset Information: num_examples: 6999, num_classes: 2\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 887\n",
      "Overall dataset quality in terms of this issue: 0.8733\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_label_issue   label_score  given_label  predicted_label\n",
      "6955            True  4.017595e-20            0                1\n",
      "4843            True  1.925082e-14            1                0\n",
      "3536            True  5.977785e-14            0                1\n",
      "5330            True  1.345679e-13            0                1\n",
      "2653            True  9.019454e-13            0                1\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 154\n",
      "Overall dataset quality in terms of this issue: 0.9506\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_outlier_issue  outlier_score\n",
      "6428              True       0.754003\n",
      "1894              True       0.760404\n",
      "5560              True       0.781842\n",
      "2079              True       0.786839\n",
      "99                True       0.792435\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 129\n",
      "Overall dataset quality in terms of this issue: 0.0393\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_near_duplicate_issue  near_duplicate_score                               near_duplicate_sets  distance_to_nearest_neighbor\n",
      "4570                     True          5.960464e-08                                            [4572]                  5.960464e-08\n",
      "4572                     True          5.960464e-08                                            [4570]                  5.960464e-08\n",
      "1806                     True          1.192093e-07                                            [1807]                  1.192093e-07\n",
      "1807                     True          1.192093e-07                                            [1806]                  1.192093e-07\n",
      "4760                     True          3.097057e-04  [4759, 4754, 4757, 4755, 4753, 4756, 4758, 4752]                  3.097057e-04\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_non_iid_issue  non_iid_score\n",
      "6860              True       0.550619\n",
      "6865             False       0.551167\n",
      "46               False       0.551459\n",
      "60               False       0.552154\n",
      "65               False       0.552719\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Please specify some issue_types to check for in imagelab.find_issues().\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from cleanlab import Datalab\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "features = torch.load('/storage/results/labeled_6999//features.pt')\n",
    "pred_probs = torch.load('/storage/results/labeled_6999/pred_probs.pt')\n",
    "dataset = torch.load('/storage/results/labeled_6999/dataset.pt')\n",
    "print(dataset)\n",
    "imgs = dataset['image']\n",
    "\n",
    "lab = Datalab(data=dataset, label_name=\"label\", image_key=\"image\")\n",
    "lab.find_issues(features=features, pred_probs=pred_probs)\n",
    "\n",
    "lab.report()\n",
    "\n",
    "\n",
    "classes ={0:'no_watermark',1:'watermark'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cad7c1-0d02-4e29-846f-7a7bc214df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = lab.get_issues(\"outlier\")\n",
    "#issues = issues.sort_values(by='outlier_score', ascending = True)\n",
    "issues = issues.loc[issues['is_outlier_issue'] == True]\n",
    "\n",
    "#issues = issues.head(2)\n",
    "print(issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59330e5b-6c4b-4649-8ebb-6abad4824971",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in imgs[issues.index]:\n",
    "    print(path)\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(2*\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb82b2-422e-4f21-8b30-06fd63a02e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = lab.get_issues(\"near_duplicate\")\n",
    "\n",
    "issues = issues.loc[issues['is_near_duplicate_issue'] == True]\n",
    "print(issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7016144-04b4-47af-bf50-05ffd68c8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890dc3d-b8c0-4cc9-aa6d-25ba2541e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in issues.iterrows():\n",
    "    #print(row['near_duplicate_sets'])\n",
    "    path = imgs[i]\n",
    "    path_dup = [imgs[l] for l in row['near_duplicate_sets']][:3]\n",
    "\n",
    "    print(path)\n",
    "\n",
    "\n",
    "    img = Image.open(path)\n",
    "\n",
    "    fig,ax = plt.subplots(1,len(path_dup)+1)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    for i,path in enumerate(path_dup):\n",
    "        #print(i)\n",
    "        img = Image.open(path)\n",
    "        ax[i+1].imshow(img)\n",
    "        ax[i+1].axis(\"off\")\n",
    "    plt.show()\n",
    "    print(2*\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101b525-de0f-4f5f-8e0e-8dd371502e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in imgs[issues.index]:\n",
    "    print(path)\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(2*\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27299931-3217-4501-b310-0a4bef23d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      given_label predicted_label                                        id  \\\n",
      "0       watermark    no_watermark                              /92085/11961   \n",
      "1       watermark    no_watermark       /2022719/arpadweb_bib_ADGD160967448   \n",
      "2       watermark    no_watermark              /91674/GSM_delobjekt_1320365   \n",
      "3       watermark    no_watermark                             /15501/011097   \n",
      "4       watermark    no_watermark                             /15501/002344   \n",
      "..            ...             ...                                       ...   \n",
      "882  no_watermark       watermark        /9200518/ark__12148_btv1b53114069p   \n",
      "883  no_watermark       watermark         /9200518/ark__12148_btv1b9052314c   \n",
      "884  no_watermark       watermark                         /9200579/kg56dtu6   \n",
      "885  no_watermark       watermark                         /9200579/zcdskcsh   \n",
      "886  no_watermark       watermark  /92064/bildarchivaustria_Preview_1234180   \n",
      "\n",
      "                                                   uri  \\\n",
      "0         https://www.europeana.eu/en/item/92085/11961   \n",
      "1    https://www.europeana.eu/en/item/2022719/arpad...   \n",
      "2    https://www.europeana.eu/en/item/91674/GSM_del...   \n",
      "3        https://www.europeana.eu/en/item/15501/011097   \n",
      "4        https://www.europeana.eu/en/item/15501/002344   \n",
      "..                                                 ...   \n",
      "882  https://www.europeana.eu/en/item/9200518/ark__...   \n",
      "883  https://www.europeana.eu/en/item/9200518/ark__...   \n",
      "884  https://www.europeana.eu/en/item/9200579/kg56dtu6   \n",
      "885  https://www.europeana.eu/en/item/9200579/zcdskcsh   \n",
      "886  https://www.europeana.eu/en/item/92064/bildarc...   \n",
      "\n",
      "                                             image_url  \n",
      "0               http://dom.lndb.lv/data/obj/file/42583  \n",
      "1    http://arquivo.galiciana.gal/arpadweb/i18n/cat...  \n",
      "2    https://samlingar.goteborgsstadsmuseum.se/carl...  \n",
      "3    https://realonline.imareal.sbg.ac.at/imageserv...  \n",
      "4    https://realonline.imareal.sbg.ac.at/imageserv...  \n",
      "..                                                 ...  \n",
      "882  https://gallica.bnf.fr/iiif/ark:/12148/btv1b53...  \n",
      "883  https://gallica.bnf.fr/iiif/ark:/12148/btv1b90...  \n",
      "884  https://iiif.wellcomecollection.org/image/L003...  \n",
      "885  https://iiif.wellcomecollection.org/image/V001...  \n",
      "886  http://www.bildarchivaustria.at/Preview/123418...  \n",
      "\n",
      "[887 rows x 5 columns]\n",
      "(887, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "metadata_path = '/storage/data/labeled_6999.csv'\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "issues = lab.get_issues(\"label\")\n",
    "issues = issues.loc[issues['is_label_issue'] == True]\n",
    "\n",
    "issues['predicted_label'] = issues['predicted_label'].apply(lambda x: classes[x])\n",
    "issues['given_label'] = issues['given_label'].apply(lambda x: classes[x])\n",
    "issues = issues.drop(columns = ['is_label_issue','label_score'])\n",
    "\n",
    "issues['id'] = [Path(path).with_suffix('').name.replace('[ph]','/') for path in imgs[issues.index]]\n",
    "\n",
    "issues = issues.merge(metadata_df, left_on='id', right_on='id')\n",
    "issues = issues.drop(columns = ['category'])\n",
    "\n",
    "print(issues)\n",
    "print(issues.shape)\n",
    "\n",
    "issues.to_csv('/storage/results/labeled_6999/images_to_review.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83b2a210-9046-455d-9b9c-a7b73d9c0b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59e3491-6afe-453c-8595-7b79cd8ade27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metadata_path = '/storage/data/labeled_6999.csv'\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df['dataset'] = metadata_df['id'].apply(lambda x: x.split('/')[1])\n",
    "\n",
    "watermarks_df = metadata_df.loc[metadata_df['category'] == 'watermark']\n",
    "watermark_datasets = watermarks_df['dataset'].unique()\n",
    "len(watermark_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b3afd6-3b04-46de-ad73-391a32621550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 5)\n",
      "(52, 5)\n",
      "(65, 5)\n",
      "(50, 5)\n",
      "(51, 5)\n",
      "(37, 5)\n",
      "(51, 5)\n",
      "(58, 5)\n",
      "(49, 5)\n",
      "(30, 5)\n",
      "(45, 5)\n",
      "(50, 5)\n",
      "(43, 5)\n",
      "(50, 5)\n",
      "(53, 5)\n",
      "(61, 5)\n",
      "(51, 5)\n",
      "(31, 5)\n",
      "(47, 5)\n",
      "(52, 5)\n",
      "(51, 5)\n",
      "(51, 5)\n",
      "(52, 5)\n",
      "(53, 5)\n",
      "(49, 5)\n",
      "(49, 5)\n",
      "(60, 5)\n",
      "(51, 5)\n",
      "(14, 5)\n",
      "(14, 5)\n",
      "(24, 5)\n",
      "(29, 5)\n",
      "(13, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(42, 5)\n",
      "(7, 5)\n",
      "(10, 5)\n",
      "(3, 5)\n",
      "(1, 5)\n",
      "(5, 5)\n",
      "(1, 5)\n",
      "(9, 5)\n",
      "(2, 5)\n",
      "(148, 5)\n",
      "(6, 5)\n",
      "(1, 5)\n",
      "(6, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(141, 5)\n",
      "(7, 5)\n",
      "(40, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(3, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(10, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(8, 5)\n",
      "(13, 5)\n",
      "(9, 5)\n",
      "(3, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(4, 5)\n",
      "(8, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(130, 5)\n",
      "(119, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(6, 5)\n",
      "(10, 5)\n",
      "(8, 5)\n",
      "(13, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(8, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(10, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(8, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(8, 5)\n",
      "(1, 5)\n",
      "(6, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(3, 5)\n",
      "(2, 5)\n",
      "(3, 5)\n",
      "(5, 5)\n",
      "(10, 5)\n",
      "(5, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(50, 5)\n",
      "(2, 5)\n",
      "(3, 5)\n",
      "(1, 5)\n",
      "(145, 5)\n",
      "(4, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(7, 5)\n",
      "(11, 5)\n",
      "(8, 5)\n",
      "(4, 5)\n",
      "(1, 5)\n",
      "(166, 5)\n",
      "(117, 5)\n",
      "(55, 5)\n",
      "(129, 5)\n",
      "(89, 5)\n",
      "(64, 5)\n",
      "(53, 5)\n",
      "(76, 5)\n",
      "(39, 5)\n",
      "(147, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(5, 5)\n",
      "(3, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(8, 5)\n"
     ]
    }
   ],
   "source": [
    "for dataset_id in watermark_datasets:\n",
    "    df = watermarks_df.loc[watermarks_df['dataset'] == dataset_id]\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99cf0048-61ef-4925-abd5-c5f92a427c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a97760-dc4d-409f-a2ca-8736dd5cb570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b845260f-050b-433e-8af9-1f74a7119057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>uri</th>\n",
       "      <th>image_url</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/916106/vbg_object_VM02937_b</td>\n",
       "      <td>watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/916106/vbg_ob...</td>\n",
       "      <td>http://mm.dimu.org/image/012uL2QqcFRs?dimensio...</td>\n",
       "      <td>916106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/11625/RBINSOPENUP_RBINS_BELGIUM_3204</td>\n",
       "      <td>watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/11625/RBINSOP...</td>\n",
       "      <td>http://projects.biodiversity.be/openup/rbins/3...</td>\n",
       "      <td>11625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/91625/nomu_object_NM0154251</td>\n",
       "      <td>watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/91625/nomu_ob...</td>\n",
       "      <td>http://mm.dimu.org/image/022s84LRRAoh?dimensio...</td>\n",
       "      <td>91625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/431/https___www_searchculture_gr_aggregator_e...</td>\n",
       "      <td>watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/431/https___w...</td>\n",
       "      <td>https://www.searchculture.gr/aggregator/thumbn...</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/91642/SMVK_OM_delobjekt_118274</td>\n",
       "      <td>watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/91642/SMVK_OM...</td>\n",
       "      <td>http://collections.smvk.se/carlotta-om/web/ima...</td>\n",
       "      <td>91642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>/946/https___www_searchculture_gr_aggregator_e...</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/946/https___w...</td>\n",
       "      <td>https://www.searchculture.gr/aggregator/thumbn...</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>/951/Culturalia_43e7ad75_ea7c_4013_934b_984c6d...</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/951/Culturali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>/951/Culturalia_96dda327_cf60_4988_aa38_5c6b5b...</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/951/Culturali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>/951/Culturalia_b7b2ee8d_8ea2_4e07_82ec_70c53b...</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/951/Culturali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>/957/BEAUVAIS_2138_000</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>https://www.europeana.eu/en/item/957/BEAUVAIS_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id      category  \\\n",
       "0                          /916106/vbg_object_VM02937_b     watermark   \n",
       "1                 /11625/RBINSOPENUP_RBINS_BELGIUM_3204     watermark   \n",
       "2                          /91625/nomu_object_NM0154251     watermark   \n",
       "3     /431/https___www_searchculture_gr_aggregator_e...     watermark   \n",
       "4                       /91642/SMVK_OM_delobjekt_118274     watermark   \n",
       "...                                                 ...           ...   \n",
       "6994  /946/https___www_searchculture_gr_aggregator_e...  no_watermark   \n",
       "6995  /951/Culturalia_43e7ad75_ea7c_4013_934b_984c6d...  no_watermark   \n",
       "6996  /951/Culturalia_96dda327_cf60_4988_aa38_5c6b5b...  no_watermark   \n",
       "6997  /951/Culturalia_b7b2ee8d_8ea2_4e07_82ec_70c53b...  no_watermark   \n",
       "6998                             /957/BEAUVAIS_2138_000  no_watermark   \n",
       "\n",
       "                                                    uri  \\\n",
       "0     https://www.europeana.eu/en/item/916106/vbg_ob...   \n",
       "1     https://www.europeana.eu/en/item/11625/RBINSOP...   \n",
       "2     https://www.europeana.eu/en/item/91625/nomu_ob...   \n",
       "3     https://www.europeana.eu/en/item/431/https___w...   \n",
       "4     https://www.europeana.eu/en/item/91642/SMVK_OM...   \n",
       "...                                                 ...   \n",
       "6994  https://www.europeana.eu/en/item/946/https___w...   \n",
       "6995  https://www.europeana.eu/en/item/951/Culturali...   \n",
       "6996  https://www.europeana.eu/en/item/951/Culturali...   \n",
       "6997  https://www.europeana.eu/en/item/951/Culturali...   \n",
       "6998  https://www.europeana.eu/en/item/957/BEAUVAIS_...   \n",
       "\n",
       "                                              image_url dataset  \n",
       "0     http://mm.dimu.org/image/012uL2QqcFRs?dimensio...  916106  \n",
       "1     http://projects.biodiversity.be/openup/rbins/3...   11625  \n",
       "2     http://mm.dimu.org/image/022s84LRRAoh?dimensio...   91625  \n",
       "3     https://www.searchculture.gr/aggregator/thumbn...     431  \n",
       "4     http://collections.smvk.se/carlotta-om/web/ima...   91642  \n",
       "...                                                 ...     ...  \n",
       "6994  https://www.searchculture.gr/aggregator/thumbn...     946  \n",
       "6995                                                NaN     951  \n",
       "6996                                                NaN     951  \n",
       "6997                                                NaN     951  \n",
       "6998                                                NaN     957  \n",
       "\n",
       "[6999 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83defbc2-8ca0-4c21-909e-286787294a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681bd023-c0fc-42f9-84d8-c3d9cdf1407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>1.426999e-02</td>\n",
       "      <td>watermark</td>\n",
       "      <td>no_watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>9.134066e-03</td>\n",
       "      <td>watermark</td>\n",
       "      <td>no_watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>1.725217e-01</td>\n",
       "      <td>watermark</td>\n",
       "      <td>no_watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>True</td>\n",
       "      <td>2.028626e-02</td>\n",
       "      <td>watermark</td>\n",
       "      <td>no_watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>True</td>\n",
       "      <td>3.516130e-02</td>\n",
       "      <td>watermark</td>\n",
       "      <td>no_watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>True</td>\n",
       "      <td>2.445217e-01</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>True</td>\n",
       "      <td>6.942308e-02</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>True</td>\n",
       "      <td>6.960711e-04</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>True</td>\n",
       "      <td>3.968944e-02</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>watermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>True</td>\n",
       "      <td>1.508075e-10</td>\n",
       "      <td>no_watermark</td>\n",
       "      <td>watermark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_label_issue   label_score   given_label predicted_label\n",
       "9               True  1.426999e-02     watermark    no_watermark\n",
       "47              True  9.134066e-03     watermark    no_watermark\n",
       "75              True  1.725217e-01     watermark    no_watermark\n",
       "87              True  2.028626e-02     watermark    no_watermark\n",
       "127             True  3.516130e-02     watermark    no_watermark\n",
       "...              ...           ...           ...             ...\n",
       "4222            True  2.445217e-01  no_watermark       watermark\n",
       "4235            True  6.942308e-02  no_watermark       watermark\n",
       "4239            True  6.960711e-04  no_watermark       watermark\n",
       "4258            True  3.968944e-02  no_watermark       watermark\n",
       "4304            True  1.508075e-10  no_watermark       watermark\n",
       "\n",
       "[539 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ebd97-5f28-43b1-b98b-09be091886ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = lab.get_issues(\"label\")\n",
    "issues = issues.loc[issues['is_label_issue'] == True]\n",
    "\n",
    "explore = 'watermark'\n",
    "\n",
    "inv_class = {v:k for k,v in classes.items()}\n",
    "issues = issues.loc[issues['predicted_label'] == inv_class[explore]]\n",
    "\n",
    "issues = issues.tail(36)\n",
    "print(issues.shape)\n",
    "\n",
    "N = 50\n",
    "\n",
    "num = 0\n",
    "\n",
    "for i,row in issues.iterrows():\n",
    "    try:\n",
    "        img = Image.open(imgs[i])\n",
    "        num += 1\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if num > N:\n",
    "        break\n",
    "\n",
    "    print(imgs[i])\n",
    "    print(f\"gt: {classes[row['given_label']]}, predicted: {classes[row['predicted_label']]}\")\n",
    "    fig,ax = plt.subplots(1,1,figsize = (10,10))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    print(2*\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f881c-61e7-44bd-a6b6-fb52738a26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dest_path = Path('/storage/data/labeled_4312/watermark/')\n",
    "\n",
    "with open('/storage/results/iter_6/to_watermarks.txt','r') as f:\n",
    "    path_list = f.readlines()\n",
    "\n",
    "for path in path_list:\n",
    "    path = Path(path.strip())\n",
    "    if not path.is_file():\n",
    "        continue\n",
    "    move(str(path),str(dest_path.joinpath(path.name)))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ec608-b74f-46ed-b51b-ceb5ba1f82e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95650e93-7bcc-4aa4-8ec3-e636dac08fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccf53f-ce92-4069-8bab-90bf7a4fea68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c0b71-0467-4d32-af61-bec1028878ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8accece-b2af-41b1-a2cd-e1b42743c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "from cleanlab import Datalab\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Method for computing out-of-sample embeddings\n",
    "def compute_embeddings(model, testloader):\n",
    "    embeddings_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            embeddings = model.embeddings(images)\n",
    "            embeddings_list.append(embeddings.cpu())\n",
    "\n",
    "    return torch.vstack(embeddings_list)\n",
    "\n",
    "\n",
    "# Method for computing out-of-sample predicted probabilities\n",
    "def compute_pred_probs(model, testloader):\n",
    "    pred_probs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            pred_probs_list.append(outputs.cpu())\n",
    "\n",
    "    return torch.vstack(pred_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70ca5d-02d8-4cd1-93fa-43f555fa519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../machine-learning')\n",
    "\n",
    "from train import Classifier, TrainingDataset, my_collate\n",
    "\n",
    "import fire\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class Classifier(pl.LightningModule): \n",
    "  \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        output_dim = kwargs.get('output_dim')\n",
    "        learning_rate = kwargs.get('learning_rate')\n",
    "        self.threshold = kwargs.get('threshold')\n",
    "\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, output_dim)\n",
    "        self.embedding = nn.Sequential(*list(self.model.children())[:-1])\n",
    "\n",
    "        #self.output = nn.Linear(self.model.fc.out_features, output_dim)\n",
    "        \n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        self.accuracy = torchmetrics.Accuracy(task='binary')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        #out = self.output(x)\n",
    "        out = self.sm(out)\n",
    "        return out\n",
    "\n",
    "    def embeddings(self, x):\n",
    "        out = self.embedding(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        y_hat = torch.where(y_hat>self.threshold,1,0).int()\n",
    "        self.accuracy(y_hat, y.int())\n",
    "        self.log('valid_acc_step', self.accuracy)\n",
    "        self.log('valid_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        y_hat = torch.where(y_hat>self.threshold,1,0).int()\n",
    "        self.accuracy(y_hat, y.int())\n",
    "        self.log('test_acc_step', self.accuracy)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad05bb-8887-4927-862e-ff25687be81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = '/output/data/labeled_4312'\n",
    "saving_dir = '/output/results/iter_7'\n",
    "\n",
    "max_epochs = 1\n",
    "sample = 0.6\n",
    "#test_size = 0.2\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "threshold = 0.5\n",
    "num_workers = 1\n",
    "patience = 5\n",
    "K = 3\n",
    "\n",
    "data_dir = Path(data_dir)\n",
    "saving_dir = Path(saving_dir)\n",
    "saving_dir.mkdir(exist_ok = True, parents=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.25),\n",
    "    #transforms.RandomRotation(degrees=(0, 45)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "imgs = np.array([str(p) for p in data_dir.rglob(\"*/*\")])\n",
    "labels = np.array([Path(p).parent.name for p in imgs])\n",
    "\n",
    "n = int(imgs.shape[0]*sample)\n",
    "imgs = imgs[:n]\n",
    "labels = labels[:n]\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "_labels = le.fit_transform(labels)\n",
    "classes = le.classes_\n",
    "labels = F.one_hot(torch.from_numpy(_labels)).float()\n",
    "\n",
    "print(len(classes))\n",
    "\n",
    "\n",
    "# Create k splits of the dataset\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0)\n",
    "splits = kfold.split(imgs, _labels)\n",
    "\n",
    "train_id_list, test_id_list = [], []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(splits):\n",
    "    train_id_list.append(train_ids)\n",
    "    test_id_list.append(test_ids)\n",
    "\n",
    "\n",
    "pred_probs_list, embeddings_list = [], []\n",
    "embeddings_model = None\n",
    "\n",
    "for i in range(K):\n",
    "    print(f\"\\nTraining on fold: {i+1} ...\")\n",
    "\n",
    "    # Create train and test sets and corresponding dataloaders\n",
    "\n",
    "    X_train_val = imgs[train_id_list[i]]\n",
    "    y_train_val = labels[train_id_list[i]]\n",
    "\n",
    "    # Create validation split\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1.0/K)\n",
    "\n",
    "    X_test = imgs[test_id_list[i]]\n",
    "    y_test = labels[test_id_list[i]]\n",
    "\n",
    "    train_dataset = TrainingDataset(X_train,y_train,transform = train_transform)\n",
    "    val_dataset = TrainingDataset(X_val,y_val,transform = test_transform)\n",
    "    test_dataset = TrainingDataset(X_test,y_test,transform = test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,collate_fn=my_collate,num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=my_collate,num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size,collate_fn=my_collate,num_workers=num_workers)\n",
    "\n",
    "    model = Classifier(\n",
    "        output_dim = len(classes), \n",
    "        learning_rate = learning_rate,\n",
    "        threshold = threshold\n",
    "    )\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor=\"valid_loss\",patience=patience, verbose = True)]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        #gpus=1,\n",
    "        accelerator=\"auto\",\n",
    "        max_epochs = max_epochs,\n",
    "        log_every_n_steps=100,\n",
    "        callbacks = callbacks\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    trainer.test(dataloaders=test_loader)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Compute out-of-sample embeddings\n",
    "    print(\"Computing feature embeddings ...\")\n",
    "    fold_embeddings = compute_embeddings(model, test_loader)\n",
    "    embeddings_list.append(fold_embeddings)\n",
    "\n",
    "    print(\"Computing predicted probabilities ...\")\n",
    "    # Compute out-of-sample predicted probabilities\n",
    "    fold_pred_probs = compute_pred_probs(model, test_loader)\n",
    "    pred_probs_list.append(fold_pred_probs)\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "\n",
    "# Combine embeddings and predicted probabilities from each fold\n",
    "features = torch.vstack(embeddings_list).numpy()\n",
    "features = np.squeeze(features)\n",
    "\n",
    "logits = torch.vstack(pred_probs_list)\n",
    "pred_probs = logits.numpy()\n",
    "\n",
    "indices = np.hstack(test_id_list)\n",
    "\n",
    "imgs = imgs[indices]\n",
    "_labels = _labels[indices]\n",
    "dataset = {'image':imgs,'label':_labels}\n",
    "\n",
    "saving_dir\n",
    "\n",
    "torch.save(features, '/output/results/features.pt')\n",
    "torch.save(dataset, '/output/results/dataset.pt')\n",
    "torch.save(pred_probs, '/output/results/pred_probs.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f3918-447d-40a0-920b-14c6f6d989fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f72ace-ef3d-4030-a42a-deca36e7cf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa09239-031a-413d-a253-2e9c8b368f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd18179-d55a-4e59-8035-1bbeb8399ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6e1fd-5a8d-401b-9a28-aae4bb06fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
